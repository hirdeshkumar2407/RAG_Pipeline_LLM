# NLP Group Project 2024/25 - RAG-Instruct Dataset

## üìö Course
Natural Language Processing, 2024/25


## üß† Project Overview
This project explores the **RAG-Instruct** dataset, a collection of 40,000 question-answer pairs where answers are automatically generated by GPT-4o based on retrieved documents. The dataset is designed for **retrieval-augmented generation (RAG)** tasks, combining elements of information retrieval and text generation.

Our goal is to:
- Perform **preliminary analysis** of the dataset structure and vocabulary
- Build and evaluate **machine learning and deep learning models** for QA and RAG tasks
- **Fine-tune pretrained models**, and explore the performance of **zero-shot, few-shot, and one-shot learning**
- Conduct **exploratory clustering and document embedding** visualizations using techniques like Word2Vec and PCA/t-SNE

## üì¶ Dataset
- **Name**: RAG-Instruct  
- **Source**: [Hugging Face](https://huggingface.co/datasets/FreedomIntelligence/RAG-Instruct)  
- **Size**: ~40,000 QA pairs  
- **Features**: Each instance includes a question, a generated answer, and retrieved documents as supporting context.

## üîç Tasks and Methods
1. **Preprocessing & Exploration**
   - Tokenization and basic NLP preprocessing
   - Vocabulary size analysis
   - Length distribution of questions and contexts

2. **Model Training**
   - Train a baseline classifier or QA model (e.g., LSTM, Transformer)
   - Fine-tune a pretrained model like BERT or T5
   - Evaluate zero-shot, one-shot, and few-shot performance of LLMs

3. **Extensions (Optional)**
   - Explore alternative tasks (e.g., summarization of documents)
   - Investigate retrieval methods and compare RAG pipelines
   - Train/fine-tune a small LLM if resources allow


---

